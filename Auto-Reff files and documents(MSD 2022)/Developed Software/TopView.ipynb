{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125e51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.exposure import equalize_hist\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from glob import glob\n",
    "from scipy.spatial.distance import cdist\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a1555",
   "metadata": {},
   "source": [
    "# Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cb8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_boxes(outputs, image_width, image_height, classes, confidence_threshold=0.4, nms_threshold=0.3):\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5]\n",
    "            class_id = np.argmax(scores)\n",
    "            class_name = classes[class_id]\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > confidence_threshold and class_name== 'Robot1':\n",
    "                cx, cy, width, height = (detection[0:4] * np.array([image_width, image_height, image_width, image_height])).astype(\"int\")\n",
    "                x = int(cx - width / 2)\n",
    "                y = int(cy - height / 2)\n",
    "                boxes.append([x, y, int(width), int(height),cx,cy])\n",
    "                confidences.append(float(confidence))\n",
    "    nms_indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, nms_threshold)\n",
    "    \n",
    "    return [boxes[ind] for ind in nms_indices.flatten()]\n",
    "def compute_point_perspective_transformation(matrix,boxes):\n",
    "    list_downoids = [[box[4], box[5]+box[3]//2] for box in boxes]\n",
    "    list_points_to_detect = np.float32(list_downoids).reshape(-1, 1, 2)\n",
    "    transformed_points = cv2.perspectiveTransform(list_points_to_detect, matrix)\n",
    "    transformed_points_list = list()\n",
    "    for i in range(0,transformed_points.shape[0]):\n",
    "        transformed_points_list.append([transformed_points[i][0][0],transformed_points[i][0][1]])\n",
    "    return np.array(transformed_points_list).astype('int')\n",
    "\n",
    "\n",
    "\n",
    "def eucledian_distance(point1, point2):\n",
    "    x1,y1 = point1\n",
    "    x2,y2 = point2\n",
    "    return sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "\n",
    "def get_birds_eye_view_image(green_box, red_box,eye_view_height,eye_view_width):\n",
    "    blank_image = cv2.imread('black_background.png')\n",
    "    \n",
    "    cv2.putText(blank_image, str(len(red_box)), (120,100), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,0,255), 4, cv2.LINE_AA) \n",
    "    cv2.putText(blank_image, str(len(green_box)), (520,100), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,255,0), 4, cv2.LINE_AA)\n",
    "    \n",
    "    for point in green_box:\n",
    "        cv2.circle(blank_image,tuple([point[6],point[7]]),20,(0,255,0),-1)\n",
    "    for point in red_box:\n",
    "        cv2.circle(blank_image,tuple([point[6],point[7]]),20,(0,0,255),-1)\n",
    "    blank_image = cv2.resize(blank_image,(eye_view_width,eye_view_height))\n",
    "    return blank_image\n",
    "\n",
    "\n",
    "def get_box_image(new_box_image,box):\n",
    "    for point in box:\n",
    "        cv2.rectangle(new_box_image,(point[0],point[1]),(point[0]+point[2],point[1]+point[3]),(0, 255, 0), 2)\n",
    "    return new_box_image\n",
    "def get_boxes(birds_eye_points,boxes):\n",
    "    boxes = []\n",
    "    new_boxes = [tuple(box) + tuple(result) for box, result in zip(boxes, birds_eye_points)]\n",
    "    for i in range(0, len(new_boxes)-1):\n",
    "            for j in range(i+1, len(new_boxes)):\n",
    "                cxi,cyi = new_boxes[i][6:]\n",
    "                cxj,cyj = new_boxes[j][6:]\n",
    "                boxes.append(new_boxes[i])\n",
    "                boxes.append(new_boxes[j])\n",
    "\n",
    "    boxes = list(set(new_boxes))\n",
    "    return (boxes)\n",
    "\n",
    "def transform_position(pos,H_matrix):\n",
    "    list_points_to_detect = np.float32(pos).reshape(-1, 1, 2)\n",
    "    transformed_points = cv2.perspectiveTransform(list_points_to_detect, H_matrix)\n",
    "    return np.asarray(transformed_points).reshape(-1)\n",
    "\n",
    "def eucledian_distance(point1, point2):\n",
    "    x1,y1 = point1\n",
    "    x2,y2 = point2\n",
    "    return sqrt((x1-x2)**2 + (y1-y2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55364491",
   "metadata": {},
   "source": [
    "# Points Choose to transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d555a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ROI and corresponding points for IPM\n",
    "ipm_pts = np.array([[0, 0],  [150,155], [660, 155], [405, 605]], dtype=np.float32)\n",
    "roi = np.array([[349, 133], [386, 236], [1220, 124], [282, 914]], dtype=np.float32)\n",
    "\n",
    "img = cv2.imread('R3_Moment.jpg')\n",
    "# Compute the IPM matrix\n",
    "H_matrix = cv2.getPerspectiveTransform(roi, ipm_pts)\n",
    "dst_size=(1080, 1920)\n",
    "# Apply the IPM matrix to the input image\n",
    "ipm = cv2.warpPerspective(img, H_matrix,dst_size)\n",
    "\n",
    "# Display the input image and the IPM result\n",
    "cv2.imshow('Input Image', img)\n",
    "cv2.imshow('IPM Result', ipm)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb665bff",
   "metadata": {},
   "source": [
    "# Import ML Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02435f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"0HPgx6Yl0BWMjeGp9Wsc\")\n",
    "project = rf.workspace().project(\"autoref\")\n",
    "model = project.version(1).model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851cdc2",
   "metadata": {},
   "source": [
    "# Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcc025d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####FARAH'S and AHMET's version with ROBOFLOW prediction\n",
    "# Open the video file for reading\n",
    "\n",
    "cap = cv2.VideoCapture(\"R2.mp4\")\n",
    "n_frames=int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# Get the video frame rate and dimensions\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create a VideoWriter object for writing the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"output.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "color_list = [(0, 255, 255), (255, 0, 0),(0, 125, 255),(0, 0, 255) ]\n",
    "\n",
    "for frame in range(n_frames):\n",
    "    # read the current frame\n",
    "    ret, img =cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    # predict on the current frame using the model\n",
    "    response = model.predict(img, confidence=40 , overlap=50)\n",
    "    # Draw predicted boxes on the frame\n",
    "    dtc = []\n",
    "    for detection in response.json()[\"predictions\"]:\n",
    "        if detection[\"class\"] == 'Ball' :\n",
    "            detection[\"class\"] = 0\n",
    "        elif detection[\"class\"] == \"Team_Blue\" :\n",
    "            detection[\"class\"] = 1\n",
    "        else:\n",
    "            detection[\"class\"] = 2\n",
    "        temp = [detection[\"x\"],\n",
    "                    detection[\"y\"],\n",
    "                    detection[\"width\"],\n",
    "                    detection[\"height\"],\n",
    "                    detection[\"confidence\"],\n",
    "                    detection[\"class\"]]\n",
    "\n",
    "        dtc.append(temp)\n",
    "    del temp\n",
    "    \n",
    "    dtc = np.array(dtc)\n",
    "    L = dtc.shape[0]\n",
    "    temp_H = [] #create a temporary array to store H_transformation results\n",
    "\n",
    "    for i in range(len(dtc)): #for every object, transform coordinates\n",
    "        temp_H.append(transform_position(dtc[i][:2], H_matrix))\n",
    "    temp_H = np.array(temp_H)\n",
    "\n",
    "    dtc = np.append(dtc, temp_H, axis = 1) #append transformed coordinates in to results array for each obj\n",
    "\n",
    "    dtc = dtc[dtc[:,5].argsort()] #sort obj wrt the class id - first one is always ball if there is one\n",
    "\n",
    "    pos_check = dtc[:, 6:] - dtc[0, 6:] #check every robots pos wrt ball position\n",
    "    dtc = np.append(dtc, pos_check, axis =1) #append relative positions in to array\n",
    "\n",
    "    box_pos = []\n",
    "    box_pos.append([dtc[:,0] - dtc[:,2]/2, dtc[:,1] - dtc[:,3]/2, dtc[:,0] + dtc[:,2]/2, dtc[:,1] + dtc[:,3]/2])\n",
    "    box_pos = np.array(box_pos).T.reshape(L,4)\n",
    "\n",
    "    dtc = np.concatenate((dtc, box_pos), axis = 1)\n",
    "    del box_pos\n",
    "   \n",
    "\n",
    "    if dtc[0][5] == 0: #if the ball is detected\n",
    "        \n",
    "        \n",
    "        #put a box for ball with proper color\n",
    "        x1 = dtc[0][-4]\n",
    "        y1 = dtc[0][-3]\n",
    "        x2 = dtc[0][-2]\n",
    "        y2 = dtc[0][-1]\n",
    "        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color_list[0], 2)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(1,len(dtc)): \n",
    "            \n",
    "            #box dimensions for every obj detected\n",
    "            x1 = dtc[i][-4]\n",
    "            y1 = dtc[i][-3]\n",
    "            x2 = dtc[i][-2]\n",
    "            y2 = dtc[i][-1]\n",
    "\n",
    "            #distance of the robots with respect to ball\n",
    "            dist = eucledian_distance(dtc[i][6:8],dtc[0][6:8])\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            #dtc[i][6/7] is pposition rel. to ball dtc[i][5] is class id            \n",
    "            if dtc[i][6] < 0 and dtc[i][7] < 0 and dtc[i][5] != 0: #if a robot is behind the ball\n",
    "                corner = dtc[i] #the robot to kick corner\n",
    "                idx_corner = i #index of the robot to kick corner\n",
    "            \n",
    "            \n",
    "            #Procedure Check\n",
    "            \n",
    "            #Same team players are allowed to 2 meters\n",
    "            if (dtc[i][5] == corner[5]):\n",
    "                if idx_corner != i: \n",
    "                    if dist < 200: \n",
    "                        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color_list[3], 2)\n",
    "                        cv2.putText(img,\"There is a violation by attacking team\", (int(x1), int(y2) + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_list[3], 2)\n",
    "                        cv2.putText(img,\"{} {:.2f}\".format(\"Distance to ball\", dist/100), (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_list[3], 2)\n",
    "\n",
    "                    else:\n",
    "                        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color_list[int(corner[5])], 2)\n",
    "                        cv2.putText(img,\"{} {:.2f}\".format(\"Distance to ball\", dist/100), (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_list[int(corner[5])], 2)\n",
    "\n",
    "                else:\n",
    "                    cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color_list[int(corner[5])], 2)\n",
    "\n",
    "                    \n",
    "                \n",
    "            #Opposing team are allowed to 3meters\n",
    "            else:\n",
    "                cv2.putText(img,\"{} {:.2f}\".format(\"Distance to ball\", dist/100), (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_list[int(dtc[i][5])], 2)\n",
    "                if dist < 300 :\n",
    "                    cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color_list[3], 2)\n",
    "                    cv2.putText(img,\"There is a violation by defending team\", (int(x1), int(y2) + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_list[3], 2)\n",
    "                else:\n",
    "                    cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color_list[int(dtc[i][5])], 2)\n",
    "\n",
    "\n",
    "        \n",
    "    # Write the frame to the output video\n",
    "    out.write(img)\n",
    "\n",
    "    # Display the frame (optional)\n",
    "    cv2.imshow(\"frame\", img)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release video capture and video writer\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
